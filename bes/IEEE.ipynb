{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from time import time\n",
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_sizes = {'Motorola-Droid-Maxx':[(2432,4320),(4320,2432)],\n",
    "#                'LG-Nexus-5x':[(3024,4032),(4032,3024)],\n",
    "#                'Sony-NEX-7':[(4000,6000),(6000,4000)],\n",
    "#                'Motorola-X':[(3120,4160),(4160,3120),(2340,4160),(4160,2340)],\n",
    "#                'iPhone-6':[(2448,3264),(3264,2448)],\n",
    "#                'Samsung-Galaxy-S4':[(2322,4128),(4128,2322)],\n",
    "#                'iPhone-4s':[(2448,3264),(3264,2448)],\n",
    "#                'Samsung-Galaxy-Note3':[(2322,4128),(4128,2322)],\n",
    "#                'Motorola-Nexus-6':[(3120,4160),(4160,3120),(3088,4160),(4160,3088)],\n",
    "#                'HTC-1-M7':[(1520,2688),(2688,1520)]\n",
    "#               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "validation_path = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = pd.read_csv('train.csv').camera.unique()\n",
    "\n",
    "df_train = pd.read_csv('data/train_team_final_v5.csv')\n",
    "\n",
    "df_cv_test = pd.read_csv('HOLDOUT_VALIDATION/Final/labels.csv')\n",
    "df_cv_test = df_cv_test[df_cv_test.is_altered == 1].copy().reset_index(drop=True)\n",
    "\n",
    "# Pseudo Labels Training\n",
    "# voting = pd.read_csv('Voting_stats_v7_corr.csv')\n",
    "# voting['fname'] = [os.path.join('test',x) for x in voting.fname]\n",
    "# voting = voting[['fname','best_camera', 'is_manip','votes']]\n",
    "# voting.columns = ['fname','camera', 'is_manip', 'votes']\n",
    "# df_train= voting[(voting.votes == 6)&(voting.is_manip == 'unalt')].copy().reset_index(drop=True)\n",
    "# df_cv_test= voting[(voting.votes != 6)&(voting.is_manip == 'unalt')].copy().reset_index(drop=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "CATEGORIES = {k: i for i, k in enumerate(cameras)}\n",
    "df_train['label'] = df_train.camera.map(CATEGORIES)\n",
    "df_cv_test['label'] = df_cv_test.camera.map(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_TO_CV = 'CV_splits_team/'\n",
    "# N_CV_FOLDS = 3\n",
    "#utils.make_cv_split(df_train,cameras,'id',N_CV_FOLDS,PATH_TO_CV,seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils; reload(utils)\n",
    "cv_scores = []\n",
    "all_preds_test = {}\n",
    "model_log = 'VGG_16_pretrained_384_ext_stage2_unalt_final'\n",
    "#for i in range(N_CV_FOLDS):\n",
    "for i in range(1):\n",
    "    t1 = time()\n",
    "    predictions_list = []\n",
    "    \n",
    "    print('*'*8,'CV_FOLD_{}'.format(i),'*'*8)\n",
    "#     df_cv_train = pd.read_csv(os.path.join(PATH_TO_CV,'CV_{}_train.csv'.format(i)))\n",
    "#     df_cv_test = pd.read_csv(os.path.join(PATH_TO_CV,'CV_{}_test.csv'.format(i)))\n",
    "#     df_cv_train = df_cv_train.merge(df_train)\n",
    "#     df_cv_test = df_cv_test.merge(df_train)\n",
    "\n",
    "    # Pseudo Labels\n",
    "    #df_cv_train = df_train[df_train.is_external == -1].copy().reset_index(drop=True)\n",
    "    df_cv_train = df_train.copy().reset_index(drop=True)\n",
    "\n",
    "    df_cv_train = df_cv_train.sample(frac=1)\n",
    "    df_cv_test = df_cv_test.sample(frac=1)\n",
    "    \n",
    "    #print(pd.crosstab(df_cv_train.is_external, df_cv_train.camera))\n",
    "    print(df_cv_train.shape)\n",
    "    print(df_cv_test.shape)\n",
    "    \n",
    "    model_name = 'VGG16'\n",
    "    preprocessing = utils.get_preprocess(model_name)\n",
    "\n",
    "    TRAIN_BATCH_SIZE = utils.get_batch_size(model_name)\n",
    "    EVALUATION_BATCH_SIZE = int(TRAIN_BATCH_SIZE*1.5)\n",
    "    \n",
    "    # Calculate number of steps\n",
    "    steps_per_epoch = df_cv_train.shape[0]//TRAIN_BATCH_SIZE * 4\n",
    "    validation_steps = df_cv_test.shape[0]//EVALUATION_BATCH_SIZE + 1\n",
    "    \n",
    "    # ****************************************************************************************\n",
    "    # Train HEAD\n",
    "    weights_path_head = \"{}_head_fold_{}.hdf5\".format(model_log,i)   \n",
    "    \n",
    "    callbacks = [\n",
    "             keras.callbacks.ModelCheckpoint(weights_path_head, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True)\n",
    "            ]\n",
    "    \n",
    "    # Initialize Model\n",
    "    model = utils.InitialiazeModel(head_only=True,weights='',model_name = model_name, lr=0.001)\n",
    "    model.fit_generator(generator = utils.train_batch_generator(df_cv_train.fname.values, df_cv_train.label.values,TRAIN_BATCH_SIZE,preprocessing),\n",
    "                    validation_data = utils.evaluation_batch_generator(df_cv_test.fname.values, df_cv_test.label.values,EVALUATION_BATCH_SIZE,preprocessing),\n",
    "                    validation_steps = validation_steps,\n",
    "                    epochs = 2,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                   max_queue_size=20,\n",
    "                    callbacks=callbacks,\n",
    "                        use_multiprocessing=False,\n",
    "                   verbose = 1)\n",
    "    \n",
    "    # ****************************************************************************************\n",
    "    # Train ALL\n",
    "    df_cv_train = df_cv_train.sample(frac=1)\n",
    "    df_cv_test = df_cv_test.sample(frac=1)\n",
    "    \n",
    "    # Callbacks\n",
    "    LOG_NAME = \"{}_0001_fold_{}\".format(model_log,i)\n",
    "    #weights_path = \"VGG_16_pretrained_ext_00001_manip.{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "    weights_path = \"{}_0001_fold_{}.hdf5\".format(model_log,i)   \n",
    "    weights_path_head = \"{}_head_fold_{}.hdf5\".format(model_log,i)\n",
    "    \n",
    "    model = utils.InitialiazeModel(head_only=False,weights=weights_path_head,model_name = model_name, lr=0.001)\n",
    "    \n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "             keras.callbacks.ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=False, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "             keras.callbacks.TensorBoard(log_dir=os.path.join('logs/',LOG_NAME))\n",
    "            ]\n",
    "    \n",
    "    model.fit_generator(generator = utils.train_batch_generator(df_cv_train.fname.values, df_cv_train.label.values,TRAIN_BATCH_SIZE,preprocessing),\n",
    "                    validation_data = utils.evaluation_batch_generator(df_cv_test.fname.values, df_cv_test.label.values,EVALUATION_BATCH_SIZE,preprocessing),\n",
    "                    validation_steps = validation_steps,\n",
    "                    epochs = EPOCHS,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)\n",
    "    \n",
    "    # ****************************************************************************************\n",
    "        # Train ALL\n",
    "#     df_cv_train = df_cv_train.sample(frac=1)\n",
    "#     df_cv_test = df_cv_test.sample(frac=1)\n",
    "    \n",
    "#     # Callbacks\n",
    "#     LOG_NAME = \"{}_00001_fold_{}\".format(model_log,i)\n",
    "#     #weights_path = \"VGG_16_pretrained_ext_00001.{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "#     weights_path = \"{}_00001_fold_{}.hdf5\".format(model_log,i) \n",
    "#     weights_path_head = \"{}_0001_fold_{}.hdf5\".format(model_log,i) \n",
    "# ERROR\n",
    "    \n",
    "#     model = utils.InitialiazeModel(head_only=False,weights=weights_path_head,model_name = model_name, lr=0.0001)\n",
    "    \n",
    "#     callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "#              keras.callbacks.ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "#                                              save_weights_only=True),\n",
    "#              keras.callbacks.TensorBoard(log_dir=os.path.join('logs/',LOG_NAME))\n",
    "#             ]\n",
    "\n",
    "#     model.fit_generator(generator = utils.train_batch_generator(df_cv_train.fname.values, df_cv_train.label.values,TRAIN_BATCH_SIZE,preprocessing),\n",
    "#                     validation_data = utils.evaluation_batch_generator(df_cv_test.fname.values, df_cv_test.label.values,EVALUATION_BATCH_SIZE,preprocessing),\n",
    "#                     validation_steps = validation_steps,\n",
    "#                     epochs = EPOCHS,\n",
    "#                     steps_per_epoch = steps_per_epoch,\n",
    "#                    max_queue_size=20,\n",
    "#                    callbacks=callbacks,\n",
    "#                    verbose = 1)\n",
    "#     # ****************************************************************************************\n",
    "#         # Train ALL\n",
    "#     df_cv_train = df_cv_train.sample(frac=1)\n",
    "#     df_cv_test = df_cv_test.sample(frac=1)\n",
    "    \n",
    "#     # Callbacks\n",
    "#     LOG_NAME = \"{}_000001_fold_{}\".format(model_log,i)\n",
    "#     #weights_path = \"VGG_16_pretrained_ext_00001.{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "#     weights_path = \"{}_000001_fold_{}.hdf5\".format(model_log,i)   \n",
    "#     weights_path_head = \"{}_00001_fold_{}.hdf5\".format(model_log,i) \n",
    "    \n",
    "#     model = utils.InitialiazeModel(head_only=False,weights=weights_path_head,model_name = model_name, lr=0.00001)\n",
    "    \n",
    "#     callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "#              keras.callbacks.ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "#                                              save_weights_only=True),\n",
    "#              keras.callbacks.TensorBoard(log_dir=os.path.join('logs/',LOG_NAME)),\n",
    "#                 keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000001, verbose=1)\n",
    "#             ]\n",
    "# #     callbacks = [\n",
    "# #              #keras.callbacks.LearningRateScheduler(utils.step_decay)\n",
    "# #             ]\n",
    "\n",
    "#     model.fit_generator(generator = utils.train_batch_generator(df_cv_train.fname.values, df_cv_train.label.values,TRAIN_BATCH_SIZE,preprocessing),\n",
    "#                     validation_data = utils.evaluation_batch_generator(df_cv_test.fname.values, df_cv_test.label.values,EVALUATION_BATCH_SIZE,preprocessing),\n",
    "#                     validation_steps = validation_steps,\n",
    "#                     epochs = EPOCHS,\n",
    "#                     steps_per_epoch = steps_per_epoch,\n",
    "#                    max_queue_size=20,\n",
    "#                    callbacks=callbacks,\n",
    "#                    verbose = 1)\n",
    "# learning rate schedule\n",
    "# def step_decay(epoch):\n",
    "#     initial_lrate = 0.001\n",
    "#     drop = 0.5\n",
    "#     epochs_drop = 2\n",
    "#     lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "#     return lrate\n",
    "# #keras.callbacks.LearningRateScheduler(step_decay)\n",
    "    \n",
    "    \n",
    "    print('Time for fold {}: {}'.format(i,time()-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Validation -------------------------------\n",
    "df_cv_test = pd.read_csv('external_validation.csv')\n",
    "df_cv_test['fname'] = [os.path.join('external_validation/',fname) for fname in df_cv_test.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils; reload(utils)\n",
    "\n",
    "testing = True\n",
    "model_name = 'VGG16'\n",
    "#weights_path = \"Final_Model_Manip.hdf5\"\n",
    "weights_path = \"Final_Model_Unalt.hdf5\"\n",
    "\n",
    "TTA = True\n",
    "augment_number_per_image = 36\n",
    "\n",
    "cv_scores = []\n",
    "all_preds_test = {}\n",
    "#for i in range(N_CV_FOLDS):\n",
    "for i in range(1):\n",
    "    predictions_list = []\n",
    "    predictions_list2 = []\n",
    "    \n",
    "    print('*'*8,'CV_FOLD_{}'.format(i),'*'*8)\n",
    "    if testing:\n",
    "        # Testing Set\n",
    "        test_images = []\n",
    "        for fname in sorted(os.listdir(test_path)):\n",
    "            if 'manip' in fname:\n",
    "                continue\n",
    "            test_images.append(os.path.join(test_path,fname))\n",
    "        df_cv_test = pd.DataFrame(test_images, columns=['fname'])\n",
    "    else:\n",
    "        print('1')\n",
    "        #df_cv_test = pd.read_csv(os.path.join(PATH_TO_CV,'CV_{}_test.csv'.format(i)))\n",
    "        #df_cv_test = df_cv_test.merge(df_train)\n",
    "    \n",
    "    probs, preds = utils.model_predict(df_cv_test.fname.values,model_name,weights_path,TTA,augment_number_per_image)\n",
    "    \n",
    "    df_cv_test['pred'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best probs to the file\n",
    "# to_save = pd.DataFrame(probs)\n",
    "# cameras = pd.read_csv('train.csv').camera.unique()\n",
    "# CATEGORIES_names = {i: k for i, k in enumerate(cameras)}\n",
    "# to_save.columns = pd.Series([int(x) for x in to_save.columns.values]).map(CATEGORIES_names).values\n",
    "# to_save['fname'] = [x.split('/')[1] for x in df_cv_test['fname']]\n",
    "# to_save.to_csv('Final_Model_Probs_Unalt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of multiple models\n",
    "# from scipy.stats.mstats import gmean\n",
    "# probs = np.mean(np.array([probs0,probs]), axis=0)\n",
    "# #preds_camera_ens = gmean(np.array([probs0,probs]), axis=0)\n",
    "# df_cv_test['pred'] = np.argmax(np.array(probs0),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logloss on validation\n",
    "from sklearn.metrics import log_loss\n",
    "y_true = [np.argmax(x == cameras) for x in df_cv_test[df_cv_test.is_altered == 0].camera]\n",
    "log_loss(y_true, probs[df_cv_test.is_altered == 0], eps=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test['pred_camera'] = cameras[df_cv_test.pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test.pred_camera.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_cv_test.camera == df_cv_test.pred_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_cv_test[df_cv_test.is_altered == 0].camera == df_cv_test[df_cv_test.is_altered == 0].pred_camera) * 0.7 + np.mean(df_cv_test[df_cv_test.is_altered == 1].camera == df_cv_test[df_cv_test.is_altered == 1].pred_camera) * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test['is_manip'] = df_cv_test.fname.str[-9:-4]\n",
    "df_cv_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balanced_pred'] = -1\n",
    "\n",
    "ix = df.fname.str.contains('manip').index\n",
    "while np.any(df.iloc[ix]['balanced_pred'] == -1):\n",
    "    for c in list(df[df.is_manip == 'manip'].camera.value_counts(normalize=True).index[::-1]):\n",
    "        idx = df[df.iloc[ix]['balanced_pred'] == -1][c].argmax()\n",
    "        df.loc[idx,'balanced_pred'] = c\n",
    "\n",
    "ix = df.fname.str.contains('unalt').index\n",
    "while np.any(df.iloc[ix]['balanced_pred'] == -1):\n",
    "    for c in list(df[df.is_manip == 'unalt'].camera.value_counts(normalize=True).index[::-1]):\n",
    "        idx = df[df.iloc[ix]['balanced_pred'] == -1][c].argmax()\n",
    "        df.loc[idx,'balanced_pred'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test['balanced_pred'] = df.balanced_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test[df_cv_test.pred != df_cv_test.balanced_pred].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test.balanced_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_test['max_prob'] = np.max(probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for fname in sorted(os.listdir(test_path)):\n",
    "    test_images.append(fname)\n",
    "test = pd.DataFrame(test_images, columns=['fname'])\n",
    "test['camera'] = cameras[df_cv_test.pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.camera.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA-36 balanced\n",
    "Motorola-Nexus-6        0.104545\n",
    "iPhone-4s               0.102273\n",
    "Samsung-Galaxy-S4       0.101515\n",
    "Motorola-X              0.100000\n",
    "Motorola-Droid-Maxx     0.099621\n",
    "iPhone-6                0.099621\n",
    "Samsung-Galaxy-Note3    0.099242\n",
    "LG-Nexus-5x             0.098485\n",
    "HTC-1-M7                0.097727\n",
    "Sony-NEX-7              0.096970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('Final_Manip.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
